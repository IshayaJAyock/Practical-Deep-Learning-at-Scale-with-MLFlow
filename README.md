# Practical-Deep-Learning-at-Scale-with-MLFlow
Practical Deep Learning at Scale with MLFlow, published by Packt
<a href="https://www.packtpub.com/product/practical-deep-learning-at-scale-with-mlflow/9781803241333"><img src="https://static.packt-cdn.com/products/9781803241333/cover/smaller" alt="Practical Deep Learning at Scale with MLFlow" height="256px" align="right"></a>

This is the code repository for [Practical Deep Learning at Scale with MLFlow](https://www.packtpub.com/product/practical-deep-learning-at-scale-with-mlflow/9781803241333), published by Packt.

**Bridge the gap between offline experimentation and online production**

## What is this book about?
The book starts with an overview of the deep learning (DL) life cycle and the emerging Machine Learning Ops (MLOps) field, providing a clear picture of the four pillars of deep learning: data, model, code, and explainability and the role of MLflow in these areas.

From there onward, it guides you step by step in understanding the concept of MLflow experiments and usage patterns, using MLflow as a unified framework to track DL data, code and pipelines, models, parameters, and metrics at scale. You'll also tackle running DL pipelines in a distributed execution environment with reproducibility and provenance tracking, and tuning DL models through hyperparameter optimization (HPO) with Ray Tune, Optuna, and HyperBand. As you progress, you'll learn how to build a multi-step DL inference pipeline with preprocessing and postprocessing steps, deploy a DL inference pipeline for production using Ray Serve and AWS SageMaker, and finally create a DL explanation as a service (EaaS) using the popular Shapley Additive Explanations (SHAP) toolbox.

By the end of this book, you'll have built the foundation and gained the hands-on experience you need to develop a DL pipeline solution from initial offline experimentation to final deployment and production, all within a reproducible and open source framework.


This book covers the following exciting features: 
* Understand MLOps and deep learning life cycle development
* Track deep learning models, code, data, parameters, and metrics
* Build, deploy, and run deep learning model pipelines anywhere
* Run hyperparameter optimization at scale to tune deep learning models
* Build production-grade multi-step deep learning inference pipelines
* Implement scalable deep learning explainability as a service
* Deploy deep learning batch and streaming inference services
* Ship practical NLP solutions from experimentation to production

If you feel this book is for you, get your [copy](https://www.amazon.com/Practical-Deep-Learning-Scale-MLflow/dp/1803241330/) today!

## Instructions and Navigations

Most of the code is specific to the package versions specified in each chapter's requirements.txt file. Please ensure compatibility by installing correct packages. Any up-to-date changes can be found in this Github repo. Please follow the readme under each chapter's code folder.

All of the code is organized into folders. For example, chapter02.

## Get to Know the Author
**Yong Liu**
has been working in big data science, machine learning, and optimization since his doctoral student years at the [University of Illinois at Urbana-Champaign (UIUC)](http://illinois.edu) and later as a senior research scientist and principal investigator at the [National Center for Supercomputing Applications (NCSA)](https://www.ncsa.illinois.edu/), where he led data science R&D projects funded by the National Science Foundation and Microsoft Research. He then joined Microsoft and AI/ML start-ups in the industry. He has shipped ML and DL models to production and has been a speaker at the [Spark/Data+AI summit](https://databricks.com/speaker/yong-liu) and [NLP summit](https://www.nlpsummit.org/continuous-pretraining-and-delivery-of-nlp-models-to-optimize-sales-engagement/). He has recently published peer-reviewed papers on [deep learning](https://onlinelibrary.wiley.com/doi/10.1002/cpe.5759), [linked data](https://www.tandfonline.com/doi/full/10.1080/17538947.2013.839007), and [knowledge-infused learning](https://aiisc.ai/KiL2021/papers/K-iL2021_paper_2.pdf) at various ACM/IEEE conferences and journals.



